{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22-12-28 17:49:14.715 pyfstat INFO    : Running PyFstat version 1.18.1+1.73ad1acd.clean\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import glob \n",
    "import pandas as pd\n",
    "import h5py # import to read hdf5\n",
    "from pathlib import Path\n",
    "import pyfstat\n",
    "from scipy import stats\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROC_TRAIN_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading files ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001121a05</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f23b2d</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00a6db666</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00f36a6ac</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010a387db</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>fe38dbe64</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>feafd0d16</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>feeca844e</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>ff5ad023f</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>ffa1d19c7</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>603 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  target                                           filename\n",
       "0    001121a05       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "1    004f23b2d       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "2    00a6db666       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "3    00f36a6ac       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "4    010a387db       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "..         ...     ...                                                ...\n",
       "598  fe38dbe64       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "599  feafd0d16       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "600  feeca844e       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "601  ff5ad023f       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "602  ffa1d19c7       1  /media/viktor/T7/gravitational-waves-kaggle-20...\n",
       "\n",
       "[603 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# root = \"/Volumes/T7/gravitational-waves/kaggle-data\"\n",
    "root = \"/media/viktor/T7/gravitational-waves-kaggle-2022\"\n",
    "\n",
    "def load_trained_files(train=True):\n",
    "   if train:\n",
    "      df = pd.read_csv(f'{root}/kaggle-data/train_labels.csv')\n",
    "      df['filename'] = f'{root}/kaggle-data/train/' + df['id'].astype(str) + \".hdf5\"\n",
    "   else:\n",
    "      test_files = glob.glob(f'{root}/kaggle-data/test/*.hdf5')\n",
    "      df = pd.DataFrame({'filename': test_files})\n",
    "      \n",
    "   return df\n",
    "print(\"[INFO] Loading files ...\")\n",
    "df = load_trained_files(train=PREPROC_TRAIN_DATA)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROC_TRAIN_DATA:\n",
    "    df = df[df[\"target\"] != -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>filename</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001121a05</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>001121a05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f23b2d</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>004f23b2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00a6db666</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>00a6db666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00f36a6ac</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>00f36a6ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010a387db</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>010a387db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>fe38dbe64</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>fe38dbe64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>feafd0d16</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>feafd0d16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>feeca844e</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>feeca844e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>ff5ad023f</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>ff5ad023f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>ffa1d19c7</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/viktor/T7/gravitational-waves-kaggle-20...</td>\n",
       "      <td>ffa1d19c7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  target                                           filename  \\\n",
       "0    001121a05       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "1    004f23b2d       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "2    00a6db666       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "3    00f36a6ac       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "4    010a387db       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "..         ...     ...                                                ...   \n",
       "595  fe38dbe64       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "596  feafd0d16       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "597  feeca844e       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "598  ff5ad023f       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "599  ffa1d19c7       1  /media/viktor/T7/gravitational-waves-kaggle-20...   \n",
       "\n",
       "          name  \n",
       "0    001121a05  \n",
       "1    004f23b2d  \n",
       "2    00a6db666  \n",
       "3    00f36a6ac  \n",
       "4    010a387db  \n",
       "..         ...  \n",
       "595  fe38dbe64  \n",
       "596  feafd0d16  \n",
       "597  feeca844e  \n",
       "598  ff5ad023f  \n",
       "599  ffa1d19c7  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"name\"] = df[\"filename\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Idea from this function takes from this notebook (ðŸ˜‡): https://www.kaggle.com/code/ayuraj/g2net-understand-the-data\n",
    "def read_data(file):\n",
    "    file = Path(file)\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        filename = file.stem\n",
    "        f = f[filename]\n",
    "        h1 = f[\"H1\"]\n",
    "        l1 = f[\"L1\"]\n",
    "        freq_hz = list(f[\"frequency_Hz\"])\n",
    "        \n",
    "        h1_stft = h1[\"SFTs\"][()]\n",
    "        h1_timestamp = h1[\"timestamps_GPS\"][()]\n",
    "        # H2 data\n",
    "        l1_stft = l1[\"SFTs\"][()]\n",
    "        l1_timestamp = l1[\"timestamps_GPS\"][()]\n",
    "        \n",
    "        return h1_stft, l1_stft\n",
    "\n",
    "def preprocess_file(file):\n",
    "    \n",
    "    h1, l1 = read_data(file)\n",
    "    \n",
    "    amplitudes = {}\n",
    "    amplitudes[\"H1\"] = h1\n",
    "    amplitudes[\"L1\"] = l1\n",
    "\n",
    "    def preprocess_amplitude(x):        \n",
    "        \n",
    "        x = x[:, 0:4096] \n",
    "        \n",
    "        # Make x.real go from -1 to 1\n",
    "        x.real = x.real / 1.E-25\n",
    "        x.imag = x.imag / 1.E-25\n",
    "        \n",
    "        # IF X is too short, we pad it randomly gneerated values using np.random.randn of mu = np.mean(x) and sigma = np.std(x)\n",
    "        if x.shape[1] < 4096:\n",
    "            x = np.pad(x, ((0,0),(0,4096-x.shape[1])), 'constant')\n",
    "                \n",
    "        \n",
    "        \n",
    "        # # if the signal is too short, we pad it with zeros\n",
    "        # if x.shape[1] < 4096:\n",
    "        #     x = np.pad(x, ((0,0),(0,4096-x.shape[1])), 'constant')\n",
    "        \n",
    "        # x is currently of shape (360, 4096)\n",
    "        x = x.reshape((360, 256,16))\n",
    "        \n",
    "        x = np.abs(x)\n",
    "        \n",
    "        # max pooling along the axis = 2\n",
    "        x = np.mean(x, axis=2)\n",
    "        # x is currently of shape (360, 256)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(\"max of x\", np.max(x))\n",
    "        \n",
    "        return np.squeeze(255 * x / np.max(x))\n",
    "    \n",
    "    amplitudes[\"H1\"] = preprocess_amplitude(amplitudes[\"H1\"])\n",
    "    amplitudes[\"L1\"] = preprocess_amplitude(amplitudes[\"L1\"])\n",
    "    \n",
    "    # make amplitudes between 0 and 1\n",
    "    amplitudes_h1 = amplitudes[\"H1\"]\n",
    "    amplitudes_l1 = amplitudes[\"L1\"]\n",
    "    \n",
    "    # stack amplitudes from both detectors\n",
    "    amplitudes = np.stack((amplitudes_h1, amplitudes_l1), axis=2)\n",
    "    amplitudes = np.squeeze(amplitudes)\n",
    "    \n",
    "    return amplitudes  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loop over all files and preprocess them. Save them to train/ if PREPROC_TRAIN_DATA is True, otherwise save them to test/\n",
    "# if PREPROC_TRAIN_DATA:\n",
    "#     output_dir = f\"train\"\n",
    "# else:\n",
    "#     output_dir = f\"test\"\n",
    "    \n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "# for i, file in enumerate(tqdm(df[\"filename\"])):\n",
    "#     amplitudes = preprocess_file(file)\n",
    "#     np.save(f\"{output_dir}/{df['name'][i]}.npy\", amplitudes)\n",
    "\n",
    "\n",
    "# # Run the above for loop in parallel    \n",
    "# # Parallel(n_jobs=8)(delayed(preprocess_file)(file) for file in tqdm(df[\"filename\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [00:38, 15.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loop over all files and preprocess them. Save them to train/ if PREPROC_TRAIN_DATA is True, otherwise save them to test/\n",
    "if PREPROC_TRAIN_DATA:\n",
    "    output_dir = f\"train\"\n",
    "else:\n",
    "    output_dir = f\"test\"\n",
    "    \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def preproc_and_save(file, name):\n",
    "    amplitudes = preprocess_file(file)\n",
    "    np.save(f\"{output_dir}/{name}.npy\", amplitudes)\n",
    "\n",
    "\n",
    "# Run the above for loop in parallel    \n",
    "Parallel(n_jobs=14)(delayed(preproc_and_save)(file, name) for file, name in tqdm(zip(df[\"filename\"].tolist(), df[\"name\"].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02e568930d87ca2b8b9cf5a6033d5857823a62aae5a168045c9638053701f372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
